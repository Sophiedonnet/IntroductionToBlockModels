\documentclass[compress,10pt]{beamer}
% version imprimable pour assistance
%\documentclass[10pt, green, handout]{beamer}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[frenchb]{babel} % le document est en français
\usepackage{rotating,amsmath}
\usepackage{graphicx,cancel}       % pour ins\'erer des figures
        % pour d\'efinir plus de couleurs
\usetheme{Malmoe}  %Applique le theme INRA (ce dernier doit être present dans le repertoire courant)
\usepackage{xcolor,colortbl}
\usepackage{array}
\usepackage{mdframed}

\usepackage{lmodern}	
\usepackage{tikz}
\usetikzlibrary{positioning,shapes,arrows}


\definecolor{dgreen}{RGB}{102,193,191}
\definecolor{lgreen}{RGB}{0,140,142}
%\setbeamercolor{structure}{fg=INRA@dinst}

\setbeamertemplate{blocks}[rounded][shadow=true]
\setbeamercolor{block title}{use = structure , fg=dgreen, bg = dgreen!35}
\setbeamercolor{normal text}{fg=black,bg=white}
\setbeamercolor{alerted text}{fg=lgreen}
\setbeamercolor{example text}{fg=lgreen}
\setbeamercolor{structure}{fg=dgreen} %d'où ce bleu par défaut
\setbeamercolor{background canvas}{parent=normal text}


 \usepackage{tikz}

\usetikzlibrary{calc,shapes,backgrounds,arrows,automata,shadows,positioning}



\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}
%\pgfdeclareimage[height=\paperheight,width=\paperwidth]{intro}{plots/plante-insecte-ombre-COLLAGE.jpg}
%\setbeamertemplate{background canvas}{\pgfuseimage{intro}}

%\newmdenv[tikzsetting={draw=black, fill=white, fill opacity =0.7, line width= 4pt}, backgroundcolor=white, leftmargin=0, rightmargin=40,innertopmargin=4pt]{titlebox}


\setbeamertemplate{frametitlecontinuation}{\insertcontinuationcountroman}

%-------------------------------------------------------------------------------
% Quelques options pdf
%-------------------------------------------------------------------------------
\hypersetup{
pdfpagemode = FullScreen, % afficher le pdf en plein \'ecran
pdfauthor   = {},%
pdftitle    = {},%
pdfsubject  = {},%
pdfkeywords = {Science,Impact},%
pdfcreator  = {PDFLaTeX,emacs,AucTeX},%
pdfproducer = {INRA}%
}


\newcommand\Wider[2][3em]{%
\makebox[\linewidth][c]{%
  \begin{minipage}{\dimexpr\textwidth+#1\relax}
  \raggedright#2
  \end{minipage}%
  }%
}

\AtBeginSection[]
{  \begin{frame}
  \frametitle{}
  \tableofcontents[currentsection, hideothersubsections]
  \end{frame} 
}


 
\usepackage{subfig} 
%variables vectorielles
\usepackage{amsmath, setspace, amsfonts, amssymb, graphics,multirow}
\newcommand{\I}{\mathbb{I}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\ICL}{\mathrm{ICL}}
\newcommand{\pen}{\mathrm{pen}}


\newcommand{\diag}{\mathop{\mathrm{diag}}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\M}{\mathcal{M}_{\bK}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\bK}{\mathbf{K}}
\newcommand{\bX}{\mathbf{Y}}
\newcommand{\Xall}{\mathbf{Y}}
\newcommand{\Zall}{\mathbf{Z}}
\newcommand{\bpi}{\mathbf{\pi}}
\newcommand{\btau}{\mathbf{\tau}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bm}{\mathbf{m}}


\title{Probabilistic models for  networks}%titre premiere page

%\subtitle{Presentation Soustitre}sp

\author{UMR Mia Paris (S. Donnet, S. Robin, S. Ouadah...) }



\date{Mars 2020, Rennes}

 

%------------------------------------------------------------------ 

\begin{document}
%-------------------------------------------------------------------------------------

\begin{frame}
\titlepage

\vspace{-.5cm}
\includegraphics[scale=.1]{plots/AgroParisTech_-_logo.PNG}
\vspace{-1.2cm}
\begin{flushright}
 \includegraphics[scale=.3]{plots/Logo-INRAE.jpg}
 \end{flushright}

\end{frame}


%-------------------------------------------------------------------------------------
%-------------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------------
%-------------------------------------------------------------------------------------
\begin{frame}
\frametitle{Network data}

\begin{center}
 \includegraphics[scale=.4]{plots/image_SBM.png}
\end{center}


\bigskip


Networks can account for 
\begin{itemize}
\item Ecological network : Food web , Co-existence networks, Host-parasite interactions, Plant-pollinator interactions,
\item Social network 
\item  Inventory datasets 
\item ... 
\end{itemize}

\bigskip

Networks may be or not bipartite: Interactions between nodes belonging to the same or to different functional group(s).

%illustration reseau

\end{frame}
%-------------------------------------------------------------------------------------

\begin{frame}
 \frametitle{Terminology}
 
 A network consists in:
 \begin{itemize}
  \item nodes/vertices which represent individuals / species /ships which may interact or not,
  \item links/edges/connections which stand for an interaction between a pair of nodes / dyads.
  
 \end{itemize}

\bigskip
 
 A network may be 
 \begin{itemize}
  \item directed / oriented (e.g. food web...),
  \item symmetric / undirected (e.g. coexistence network),
  \item with or without loops.
 \end{itemize}

This distinction only makes sense for simple networks (not bipartite).
 
 
\end{frame}

%-------------------------------------------------------------------------------------


\begin{frame}
 \frametitle{Available data}

 
\begin{center}
 \includegraphics[scale=.6]{plots/image_SBM.png}
\end{center}

\begin{itemize}
 \item  the network provided as:
\begin{itemize}
 \item an adjacency matrix (for simple network) or an incidence matrix (for bipartite network),
 \item a list of pair of nodes / dyads which are linked.
\end{itemize}

\item some additional covariates on nodes, dyads which can account for sampling effort.
 \end{itemize}






\end{frame}



%-------------------------------------------------------------------------------------

\begin{frame}
 \frametitle{Goal}


 
 
\begin{center}
 \includegraphics[scale=.6]{plots/image_SBM.png}
\end{center}

\begin{itemize}
 \item Unraveling / describing / modeling the network topology. 
 \item Discovering particular structure of interaction between some subsets of nodes.
 \item Understanding network heterogeneity.
 \item Not inferring the network !
 \end{itemize}


\end{frame}



%-------------------------------------------------------------------------------------

\begin{frame}
\frametitle{Network representation and adjacency matrix}

 \begin{columns}
 \begin{column}{.45\paperwidth}
$$Y=\left(
\begin{array}{rrrrr}
0 & 1 & 0 & 0 \\ 
1 & 0 & 1 & 1 \\ 
0 & 0 & 0 & 0 \\ 
1 & 1 & 0 & 0 \\ 
\end{array}\right)
$$
\end{column}

\begin{column}{.5\paperwidth}

\includegraphics[scale=.3]{plots/graphe_adj.pdf}

\end{column}

\end{columns}

\begin{itemize}
\item $n$ rows and $n$ columns,
\item symmetric or not.
\end{itemize}

\end{frame}



%-------------------------------------------------------------------------------------

\begin{frame}
\frametitle{Bipartite network and incidence matrix}
 \begin{columns}
 \begin{column}{.45\paperwidth}
$$Y=\left(
\begin{array}{rrrrrrr}
1 &   0 &   1 &   0 &   0 &   0 &   1 \\ 
0 &   0 &   0 &   0 &   0 &   0 &   0 \\ 
0 &   0 &   0 &   1 &   0 &   1 &   0 \\ 
0 &   1 &   0 &   0 &   1 &   1 &   0 \\ \end{array}\right)
$$


\begin{itemize}
 \item n rows and m columns, rectangular matrix.
 \item corresponding adjacency matrix $(n+m)\times(n+m)$:
 $$
 \left(
 \begin{array}{rr}
  0 & Y\\
  Y^T & 0
 \end{array}
 \right)
 $$
\end{itemize}



\end{column}

\begin{column}{.5\paperwidth}

\includegraphics[scale=.3]{plots/graphe_bipartite.pdf}

\end{column}

\end{columns}



\end{frame}



%-------------------------------------------------------------------------------------
%-------------------------------------------------------------------------------------
\section{Descriptive statistics}
%-------------------------------------------------------------------------------------
%-------------------------------------------------------------------------------------


\begin{frame}
\frametitle{Some common features studied on networks}


% ref a mettre et sans doute à partager en plusieurs slides à la siute
\begin{itemize}

\item Degree distribution, can be viewed as a measure of heterogeneity,
\item Nestedness: a network is said to be nested when its nodes that have the smallest degree, are connected to nodes with the highest degree,
\textcolor{blue}{\cite{Rodriguez2006}}

\item Betweenness centrality: for a node, numbers of shortest paths between any pair of nodes passing through this node.
\textcolor{blue}{\cite{FREEMAN1978215}}

\item Modularity: is a measure for a given partition of its tendency of favoring intra-connection over inter-connection.  
$\Rightarrow$ Finding the best partition with respect to modularity criterion. 
\textcolor{blue}{\cite{clauset2008hierarchical}}
\end{itemize}
\end{frame}


%-------------------------------------------------------------------------------------
\begin{frame}
\frametitle{Some common features studied on networks}

All this criterion shall be adapted to:
\begin{itemize}
 \item directed network,
 \item bipartite network.
\end{itemize}

\bigskip

\textcolor{blue}{R packages: igraph, sna, vegan.} 


\end{frame}


%-------------------------------------------------------------------------------------


\begin{frame}
 \frametitle{Example Chilean food web}
 
\begin{center}
\includegraphics[scale=.3]{plots/chilean_food_web.pdf} 
\end{center}

\begin{itemize}
 \item $n=106$ species / nodes,
 \item density of edges: $12.1\%$.
\end{itemize}


\textcolor{blue}{\cite{kefi}}

\end{frame}


\begin{frame}
 \frametitle{Degree distribution}
 
 \begin{center}
\includegraphics[scale=.3]{plots/chilean_outdeg.pdf}  
\includegraphics[scale=.3]{plots/chilean_intdeg.pdf}
\end{center}

\end{frame}

%-------------------------------------------------------------------------------------
\begin{frame}
 \frametitle{Nestedness}
 
 \begin{center}
  \includegraphics[scale=.3]{plots/chilean_nested.pdf}
 \end{center}


 \begin{itemize}
  \item more generally used on incidence matrices,
  \item significance of the nestedness index computed by random permutations of the matrix,
  \item this food web is found to be nested.
 
 \end{itemize}

 \end{frame}

%-------------------------------------------------------------------------------------
\begin{frame}[fragile]
 \frametitle{Betweenness}
 
 \begin{center}
  \includegraphics[scale=.3]{plots/chilean_between.pdf}
 \end{center}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.000   0.000   0.000   6.604   6.929  59.570
\end{verbatim} 
 
\end{frame}

%-------------------------------------------------------------------------------------

\begin{frame}
 \frametitle{Modularity}
\begin{center}
  \includegraphics[scale=.3]{plots/chilean_modularity.pdf}
 \end{center}
 
 
 
 \begin{itemize}
  \item
  \begin{tabular}{rrrrr}
  \hline
 1 & 2 & 3 & 4 \\ 
  \hline
  69 &  17 &   7 &  13 \\ 
   \hline
\end{tabular}
\item very low modularity.
 \end{itemize}

 
\end{frame}

 
%-------------------------------------------------------------------------------------
%-------------------------------------------------------------------------------------
\section{Probabilistic  model}
%-------------------------------------------------------------------------------------
%-------------------------------------------------------------------------------------


\begin{frame}
\frametitle{A first random graph model for network: null model}

\textcolor{blue}{Erd\H{o}s-Rényi (1959)} Model for $n$ nodes 

$$\forall 1\le i,j\le n,\quad Y_{ij}\overset{i.i.d.}{\sim} b(p),$$
where $b$ is the Bernoulli distribution and $p\in[0,1]$ a probability for a link to exist. 


\begin{center}
 \includegraphics[scale=.3]{plots/ER.pdf} \includegraphics[scale=.3]{plots/degER.pdf}
\end{center}


\end{frame}

%-------------------------------------------------------------------------------------

\begin{frame}
 \frametitle{Limitations of an ER graph to describe real networks}
 
 
 
\begin{itemize}
 \item Degree distribution too concentrated, no high degree nodes,
 \item All nodes are equivalent (no nestedness...),
 \item No modularity.

 \end{itemize}

\end{frame}


%-------------------------------------------------------------------------------------
\subsection[SBM]{Stochastic Block Model}

\begin{frame}  \frametitle{Stochastic Block Model}

\textcolor{blue}{\cite{nowickiSnijders2001}}
Let ($Y_{ij}$) be an adjacency matrix 

\begin{block}{Latent variables}
\begin{itemize}
\item The nodes $i= 1,\dots,n$ are partitionned into $K$ clusters
\item $Z_i = k$ if node $i$ belongs to cluster (block) $k$
\item $Z_i$ independant variables
$$ \mathbb{P}(Z_i = k) = \pi_k$$
\end{itemize}
\end{block}

\begin{block}{Conditionally to $(Z_i)_{i=1,\dots,n}$... }

$(Y_{ij})$ independant and 
\begin{eqnarray*}
 Y_{ij}  | Z_i, Z_j \sim  \mathcal{B}ern(\alpha_{Z_i,Z_j}) \quad \Leftrightarrow \quad  P(Y_{ij} = 1 | Z_i = k, Z_j = \ell)  =  \alpha_{k\ell}
\end{eqnarray*}
\end{block}
 


\end{frame}


%-------------------------------------------------------------------------------------

\begin{frame}
  \frametitle{Stochastic Block Model : illustration}

  \begin{center}
    \begin{overlayarea}{\textwidth}{.5\textheight}
      \begin{columns}
        \begin{column}{.45\paperwidth}
        \begin{tikzpicture}
          %% UN GRAPH

          \tikzstyle{every edge}=[-,>=stealth',shorten >=1pt,auto,thin,draw]
          \tikzstyle{every state}=[draw=none,text=white,scale=0.65, font=\scriptsize, transform shape]
          \tikzstyle{every node}=[fill=yellow!40!orange]
          % premier cluster
          \node[state] (A1) at (0,0.5) {A1};
          \node[state] (A2) at (1,0.5) {A2};
          \node[state] (A3) at (.5,1.5) {A3};

          \path (A2) edge [bend left] node[fill=white,below=.1cm]
          {$\alpha_{\textcolor{yellow!40!orange}{\bullet}\textcolor{yellow!40!orange}{\bullet}}$}
          (A1)
          (A1) edge [bend left] (A3)
          (A3) edge [bend left] (A2);

          \tikzstyle{every node}=[fill=blue!80!black]
          \foreach \angle/\text in {234/B1, 162/B2, 90/B3, 18/B4, -54/B5} {
            \node[fill=blue,state,xshift=5cm,yshift=3.5cm]     (\text)    at
            (\angle:1cm) {\text};
          }
          \path (B2) edge (B5)
          (B1) edge (B4);
          \foreach \from/\to in {1/2,2/3,4/5,5/1}{
            \path (B\from) edge [bend left] (B\to);
          }

          \path    (B3)    edge     [bend    left]    node[fill=white]
          {$\alpha_{\textcolor{blue!80!black}{\bullet}\textcolor{blue!80!black}{\bullet}}$}  (B4) ;
          
          \tikzstyle{every node}=[fill=green!50!black]
          % troisieme cluster
          \node[state] (C1) at (3,-.5) {C1};
          \node[state] (C2) at (4,0) {C2};

          \path (C1) edge [bend right] node[fill=white,below=.25cm]
          {$\alpha_{\textcolor{green!50!black}{\bullet}\textcolor{green!50!black}{\bullet}}$}
          (C2);

          % inter cluster
          \path (A3) edge [bend right]  (B2)
          (A3)    edge    [bend    left]    node[fill=white]
          {$\alpha_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}}$}
          (B3)
          (C2) edge [bend right] node[fill=white,right]
          {$\alpha_{\textcolor{blue!80!black}{\bullet}\textcolor{green!50!black}{\bullet}}$}
          (B4)
          (A2) edge [bend right] node[fill=white]
          {$\alpha_{\textcolor{yellow!40!orange}{\bullet}\textcolor{green!50!black}{\bullet}}$}
          (C1);
        \end{tikzpicture}
        \end{column}


        \begin{column}{.5\paperwidth}
          \begin{small}
            \begin{block}{Parameters}
              Let $n$ nodes divided into $3$ clusters
              \begin{itemize}
              \item
                $\mathcal{K}=\{\textcolor{yellow!40!orange}{\bullet},\textcolor{blue!80!black}{\bullet},\textcolor{green!50!black}{\bullet}\}$
                 clusters
              \item  $\pi_\bullet  =  \mathbb{P}(i  \in  \bullet)$,
                $\bullet\in\mathcal{K},i=1,\dots,n$
              \item      $\alpha_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}}     =      \mathbb{P}(i
                \leftrightarrow j | i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet})$
              \end{itemize}
            \end{block}
          \end{small}
        \end{column}
      \end{columns}
    \end{overlayarea}
  \end{center}
  
%\begin{eqnarray*}
%&(Z_i) &  \ \sim^{\text{iid}} \mathcal{M}(1,\alpha) \ \text{et} \  Z_{i} \in \{1,...,Q\}, \\ 
% &(Y_{ij})&| \ \{Z_{i},Z_{j}\} \sim^{\text{ind}} \mathcal{B}(\pi_{Z_{i}Z_{j}}).\\
%\end{eqnarray*}

% Proposition Julien
\begin{align*}
Z_i = \mathbf{1}_{\{i \in \bullet\}}  \ & \sim^{\text{iid}} \mathcal{M}(1,\pi), \quad \forall\bullet \in \mathcal{K}, \\ 
Y_{ij} \ | \ \{i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet}\}
& \sim^{\text{ind}} \mathcal{B}(\alpha_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}})\\
\end{align*}

\end{frame}


%-------------------------------------------------------------------------------------


\begin{frame}
\frametitle{SBM : A great generative model}

\begin{itemize}
\item  Generative model : easy to simulate
\item No a priori on the type of structure
\item Combination of modularity, nestedness, etc... 
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------------

\begin{frame}
\frametitle{Networks with hubs generated by SBM}

\centering
\begin{tabular}{ccc}
 \includegraphics[scale=.2]{plots/sbm/Etoile_reordered_adja_with_groups.png}&
\includegraphics[scale=.2]{plots/sbm/Etoile_graphe_with_colors.png}&
   \includegraphics[scale=.2]{plots/sbm/Etoile_graphe_resume.png}
 \end{tabular}

\begin{tabular}{cc}
    \includegraphics[scale=.2]{plots/sbm/Etoile_histogram_degree.png}&
   \includegraphics[scale=.2]{plots/sbm/Etoile_betweeness.png}
 \end{tabular}

\end{frame}



%-------------------------------------------------------------------------------------
\begin{frame}
\frametitle{Community network  generated by SBM}

\centering
\begin{tabular}{cc}
 \includegraphics[scale=.2]{plots/sbm/Affiliation_reordered_adja_with_groups.png}&
\includegraphics[scale=.2]{plots/sbm/Affiliation_graphe_with_colors.png} 
 \end{tabular}

\begin{tabular}{cc}
   \includegraphics[scale=.2]{plots/sbm/Affiliation_graphe_resume.png}
    \includegraphics[scale=.2]{plots/sbm/Affiliation_histogram_degree.png}&
 \end{tabular}

\end{frame}


%-------------------------------------------------------------------------------------
\begin{frame}
\frametitle{Nestedness  generated by SBM}

\centering
\begin{tabular}{cc}
 \includegraphics[scale=.2]{plots/sbm/Nested_reordered_adja_with_groups.png}&
\includegraphics[scale=.2]{plots/sbm/Nested_graphe_with_colors.png} 
 \end{tabular}

\begin{tabular}{cc}
   \includegraphics[scale=.2]{plots/sbm/Nested_graphe_resume.png}
    \includegraphics[scale=.2]{plots/sbm/Nested_histogram_degree.png}&
 \end{tabular}

\end{frame}



%-------------------------------------------------------------------------------------

\begin{frame}
  \frametitle{Statistical inference}
 
    \begin{center}
  \begin{overlayarea}{\textwidth}{.5\textheight}
      \begin{columns}
        \begin{column}{.45\paperwidth}
        \begin{tikzpicture}
          %% UN GRAPH

          \tikzstyle{every edge}=[-,>=stealth',shorten >=1pt,auto,thin,draw]
          \tikzstyle{every state}=[draw=none,text=white,scale=0.65, font=\scriptsize, transform shape]
          \tikzstyle{every node}=[fill=lightgray]
          % premier cluster
          \node[state] (A1) at (0,0.5) {N1};
          \node[state] (A2) at (1,0.5) {N2};
          \node[state] (A3) at (.5,1.5) {N3};

          \path (A2) edge [bend left] node[fill=white,below=.1cm]
          {}
          (A1)
          (A1) edge [bend left] (A3)
          (A3) edge [bend left] (A2);

          \tikzstyle{every node}=[fill=blue!80!black]
          \foreach \angle/\text in {234/N1, 162/N2, 90/N3, 18/N4, -54/N5} {
            \node[fill=lightgray,state,xshift=5cm,yshift=3.5cm]     (\text)    at
            (\angle:1cm) {\text};
          }
          \path (B2) edge (B5)
          (B1) edge (B4);
          \foreach \from/\to in {1/2,2/3,4/5,5/1}{
            \path (B\from) edge [bend left] (B\to);
          }

          \path    (B3)    edge     [bend    left]    node[fill=white]
          {}  (B4) ;
          
          \tikzstyle{every node}=[fill=lightgray]
          % troisime cluster
          \node[state] (C1) at (3,-.5) {N1};
          \node[state] (C2) at (4,0) {N2};

          \path (C1) edge [bend right] (C2);

          % inter cluster
          \path (A3) edge [bend right]  (B2)
          (A3)    edge    [bend    left]    node[fill=white]
          {}
          (B3)
          (C2) edge [bend right] node[fill=white,right]
          {}
          (B4)
          (A2) edge [bend right] node[fill=white]
          {}
          (C1);
        \end{tikzpicture}
        \end{column}
        \begin{column}{.5\paperwidth}
          \begin{small}
            \begin{block}{Stochastic Block Model}
              Let $n$ nodes divided into
              \begin{itemize}
              \item
                $\mathcal{K}=\{\textcolor{yellow!40!orange}{\bullet},\textcolor{blue!80!black}{\bullet},\textcolor{green!50!black}{\bullet}\}$,
                $\text{card}(\mathcal{K})$ known
              \item  $\pi_\bullet  =  ?$,
              \item      $\alpha_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}}     =      ?$
              \end{itemize}
            \end{block}
          \end{small}
        \end{column}
      \end{columns}
    \end{overlayarea}
    \end{center}
    \medskip

    
    \textcolor{blue}{\cite{nowickiSnijders2001}, \cite{daudin2008mixture}}
    
    \bigskip
    
\textcolor{blue}{R package: blockmodels.}
%     
%     \begin{thebibliography}{99}
%       \begin{scriptsize}
%       \bibitem[NS]{NS} Nowicki, Snijders, JASA, 2001 \newblock Estimation and prediction for
%         stochastic   blockstructures.
%         \textcolor{black}{} 
%       \bibitem[DRP]{DRP}   Daudin,  Picard,   Robin,  Statistics   and
%         Computing, 2008 \newblock A mixture model for random graphs. 
%       \end{scriptsize}
%   \end{thebibliography}

\end{frame}

%-------------------------------------------------------------------------------------

\begin{frame}\frametitle{Statistical inference} 

From.... 

\centering
\begin{tabular}{cc}
 \includegraphics[scale=.2]{plots/sbm/Nested_adja.png}&
 \includegraphics[scale=.2]{plots/sbm/Nested_graphe_without_colors.png}
\end{tabular}
\end{frame}


%-------------------------------------------------------------------------------------
\begin{frame}\frametitle{Statistical inference} 

... to 

\centering
\begin{tabular}{cc}
\includegraphics[scale=.2]{plots/sbm/Nested_reordered_adja_with_groups.png}
\includegraphics[scale=.2]{plots/sbm/Nested_graphe_with_colors.png}
\end{tabular}

\begin{block}{Statistician job}
\begin{itemize}
\item Find the clusters
\item Find the number of clusters
\item Practical implementation
\item Theoretical results
\end{itemize}
\end{block}


Details  given later. 

\end{frame}




%-------------------------------------------------------------------------------------

\subsection[LBM]{Latent block models}
%reseau interaction qcq

\begin{frame}{Probabilistic model for binary  bipartite networks}

Let $Y_{ij}$ be a bi-partite network. Individuals in row and cols are not the same. 

\begin{block}{Latent variables : bi-clustering}
\begin{itemize}
\item Nodes $i= 1,\dots,n_1$   partitionned into $K_1$ clusters,  nodes $j= 1,\dots,n_2$  partitionned into $K_2$ clusters
\item $$\begin{array}{cl}
Z^1_i = k & \mbox{if node $i$ belongs to cluster (block) $k$}\\
Z^2_j = \ell & \mbox{if node $j$ belongs to cluster (block) $\ell$}
\end{array}$$
\item $Z^1_i, Z^2_j$ independent variables
$$ \mathbb{P}(Z^1_i = k) = \pi^1_k,\quad  \mathbb{P}(Z^2_j = \ell) = \pi^2_\ell$$
\end{itemize}
\end{block}

\end{frame}

%-------------------------------------------------------------------------------------

\begin{frame}{Probabilistic model for binary  bipartite networks}


\begin{block}{Conditionally to $(Z^1_i)_{i=1,\dots,n_1},(Z^2_j)_{j=1,\dots,n_2}$... }

$(Y_{ij})$ independent and 
\begin{eqnarray*}
 Y_{ij}  | Z^1_i, Z^2_j \sim  \mathcal{B}ern(\alpha_{Z^1_i,Z^2_j}) \quad \Leftrightarrow \quad   \mathbb{P}(Y_{ij} = 1 | Z^1_i = k, Z^2_j = \ell)  =  \alpha_{k\ell}
\end{eqnarray*}
\end{block}
 

\textcolor{blue}{\cite{Govaert2008}}

\end{frame}

%-------------------------------------------------------------------------------------


\begin{frame}
\frametitle{Latent Block Model : illustration}

 \begin{center}
    \begin{overlayarea}{\textwidth}{.5\textheight}
      \begin{columns}
        \begin{column}{.45\paperwidth}
        \centering
        \includegraphics[scale=.3]{plots/LBM_exemple.pdf}
        \end{column}
        \begin{column}{.5\paperwidth}
          \begin{small}
            \begin{block}{Latent Block Model}
              \begin{itemize}
              \item
                $n_1$ row nodes $\mathcal{K}_1=\{\textcolor{red}{\bullet},\textcolor{orange}{\bullet},\textcolor{green}{\bullet}\}$
                classes
              \item  $\pi^1_\bullet  =  \mathbb{P}(i  \in  \bullet)$,
                $\bullet\in\mathcal{K}_1,i=1,\dots,n$
              \item $n_2$ column nodes $\mathcal{K}_2=\{\textcolor{yellow}{\bullet},\textcolor{black}{\bullet}\}$
                classes
               \item  $\pi^2_\bullet  =  \mathbb{P}(j  \in  \bullet)$,
                $\bullet\in\mathcal{K}_2,j=1,\dots,m$
              \item      $\alpha_{\textcolor{red}{\bullet}\textcolor{yellow}{\bullet}}     =      \mathbb{P}(i
                \leftrightarrow j | i\in\textcolor{red}{\bullet},j\in\textcolor{yellow}{\bullet})$
              \end{itemize}
            \end{block}
          \end{small}
        \end{column}
      \end{columns}
    \end{overlayarea}
  \end{center}
  
%\begin{eqnarray*}
%&(Z_i) &  \ \sim^{\text{iid}} \mathcal{M}(1,\alpha) \ \text{et} \  Z_{i} \in \{1,...,Q\}, \\ 
% &(Y_{ij})&| \ \{Z_{i},Z_{j}\} \sim^{\text{ind}} \mathcal{B}(\pi_{Z_{i}Z_{j}}).\\
%\end{eqnarray*}

% Proposition Julien
\begin{align*}
Z^1_i = \mathbf{1}_{\{i \in \bullet\}}  \ & \sim^{\text{iid}} \mathcal{M}(1,\bpi^1), \quad \forall\bullet \in \mathcal{Q}_1, \\ 
Z^2_j=\mathbf{1}_{\{j \in \bullet\}}  \ & \sim^{\text{iid}} \mathcal{M}(1,\bpi^2), \quad \forall\bullet \in \mathcal{Q}_2, \\
Y_{ij} \ | \ \{i\in\textcolor{red}{\bullet},j\in\textcolor{yellow}{\bullet}\}
& \sim^{\text{ind}} \mathcal{B}ern(\alpha_{\textcolor{red}{\bullet}\textcolor{yellow}{\bullet}})\\
\end{align*}


\textcolor{blue}{\cite{Govaert2008}} and 
\textcolor{blue}{R package: blockmodels} as well.

\end{frame}





%---------------------------------------------------------------------------

\subsection{Some possible extensions}


\begin{frame}
 \frametitle{Valued-edge networks}
 

\begin{block}{Values-edges networks}
 Information on edges can be something different from presence/absence.
 It can be:
 \begin{enumerate}
  \item a count of the number of observed interactions,
  \item a quantity interpreted as the interaction strength,
  \end{enumerate}

 \end{block}

 \bigskip
 
 


\begin{block}{ Natural extensions of SBM and LBM}
 \begin{enumerate}
  \item Poisson distribution: $Y_{ij} \ | \ \{i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet}\}
\sim^{\text{ind}} \mathcal{P}(\lambda_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}})$,
 \item Gaussian distribution: $Y_{ij} \ | \ \{i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet}\}
\sim^{\text{ind}} \mathcal{N}(\mu_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}},\sigma^2)$,
\textcolor{blue}{\cite{mariadassou2010uncovering}}
\item More generally, 
  $$Y_{ij} \ | \ \{i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet}\}
\sim^{\text{ind}} \mathcal{F}(\theta_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}})$$
 \end{enumerate}
 \end{block}
 \bigskip

\end{frame}

%---------------------------------------------------------------------------

\begin{frame} \frametitle{Multiplex networks}

Several kind of interactions between nodes . 
For instance : 


\begin{itemize}
\item Love and friendship
\item Working relations and friendship
\item  In ecology : mutualistic and competition
\end{itemize}


\begin{block}{Block model for multiplex networks}

$Y_{ij} \in \{0,1\} ^ Q = (Y_{ij}^a, Y_{ij}^b)$, $\forall w \in \{0,1\}^2$ 



$$\mathbb{P}(Y^a_{ij},Y^b_{ij} = w  | Z_i  = k, Z_j = \ell)  = \alpha^w _{k\ell}$$

\end{block}

\textcolor{blue}{
\cite{kefi}, \cite{barbillon2017stochastic}}

In \textcolor{blue}{R package: blockmodels} when two relations are at stake.
 

 \textbf{Remark:} a particular case of multiplex network is dynamic network, \textcolor{blue}{\cite{matias2017statistical}}.
 

 \end{frame}
%------------------------------------------------------ 



 
\begin{frame}
 \frametitle{Taking into account covariates}
 
 Sometimes covariates are available. They may be on:
 \begin{itemize}
  \item nodes,
  \item edges,
  \item both.
 \end{itemize}

 
 
 \begin{enumerate}
  \item They can be used a posteriori to explain blocks inferred by SBM.
  \item Extension of the SBM which takes into account covariates. Blocks are structure of interaction which is not 
  explained by covariates !

 \end{enumerate}


 If covariates are sampling conditions, case 2  be  may more interesting.
 
\end{frame}


%-------------------------------------------------------------------------- 
\begin{frame}
 \frametitle{SBM with covariates}


\begin{itemize}
\item As before :  ($Y_{ij}$) be an adjacency matrix 
\item  Let   $x^{ij} \in \mathbb{R}^p$  denote covariates describing the pair $(i,j)$
\end{itemize}

\begin{block}{Latent variables : as before }
\begin{itemize}
\item The nodes $i= 1,\dots,n$ are partitioned into $K$ clusters
\item $Z_i$ independent variables
$$ \mathbb{P}(Z_i = k) = \pi_k$$
\end{itemize}
\end{block}
 
\begin{block}{Conditionally to $(Z_i)_{i=1,\dots,n}$... }

$(Y_{ij})$ independent and 
\begin{eqnarray*}
 Y_{ij}  | Z_i, Z_j&\sim&   \mathcal{B}ern(\mbox{logit}(\alpha_{Z_i,Z_j} + \theta \cdot x_{ij}) ) \quad \mbox {if binary data} \\
 Y_{ij}  | Z_i, Z_j  &\sim&  \mathcal{P}(\exp(\alpha_{Z_i,Z_j} + \theta  \cdot x_{ij}) ) \quad \mbox {if counting data} 
\end{eqnarray*}
\end{block}


If $K = 1$ : all the connection heterogeneity is explained by the covariates. 
 \end{frame}

 
%---------------------------------------------------------------------------------------------

\section{Inference}

\begin{frame}\frametitle{Statistical Inference}

\begin{itemize}
\item Selection of the number of clusters $K$ for SBM  or $K_1,K_2$ for LBM
\item Estimation of the parameters $\mathbf{\pi}, \btheta$ for a given number of clusters
\item Clustering $\hat \bZ$
\end{itemize}

\end{frame}


%---------------------------------------------------------------------------------------------

\subsection{Parameters estimation}

\begin{frame} \frametitle{Likelihood for SBM}

 \begin{block}{Complete  likelihood $(\bY)$  et  $(\bZ)$}
 \begin{eqnarray}\label{eq:lik}
\ell_c(\bY,\bZ; \theta) &=& p(\bY | \bZ; \balpha) p(\bZ ; \bpi)\nonumber  \\
&=& \prod_{i,j} f_{\alpha_{Z_i,Z_j}}(Y_{ij}) \times   \prod_{i} \pi_{Z_i} \nonumber  \\
&=&  \prod_{i,j} \alpha_{Z_i,Z_j}^{Y_{ij}} (1-  \alpha_{Z_i,Z_j})^{1- Y_{ij}}    \prod_{i} \pi_{Z_i} \nonumber
\end{eqnarray}
 
 \end{block}
 

\begin{block}{Marginal likelihood $(\bY)$}
\begin{equation}\label{eq:vraismarg}
\log \ell(\bY; \theta) =\log \sum_{\bZ \in \boldsymbol{\mathcal{Z}}} \ell_c(\bY,\bZ; \theta) \,.
\end{equation}
 \end{block}
 

 \end{frame}
 

 
 
 

%------------------------------------------------------------------------------------------------------
 \begin{frame}{Marginal likelihood  : remark }
 
 $$
\log \ell(\bY; \theta) =\log \sum_{\bZ \in \boldsymbol{\mathcal{Z}}} \ell_c(\bX,\bZ; \theta) \,.
$$
 
  \begin{block}{Remark}
$\boldsymbol{\mathcal{Z}} =  \mathop{\otimes}_{q=0\dots Q} \{1,\dots, K_q\}^{n_q}$ \color{dgreen} $\Rightarrow$ \color{black}  when  $K$ and $n$ increase, impossible to compute. 
 \end{block}
 
\color{dgreen} \textbf{Standard tool to maximize the likelihood when latent variables involved} \color{black} : EM  algorithm.  
 
 \end{frame}
 
 %------------------------------------------------------------------------------------------------------
 \begin{frame}{From EM to variational EM}

 
\begin{block}{Standard EM}
At iteration $(t)$ : 
\begin{itemize}
 \item[$\bullet$]\textbf{Step E}: compute 
 $$ Q(\theta | \theta^{(t-1)}) =   \mathbb E_{\color{dgreen}\bZ | \bX, \theta^{(t-1)} } \left[\log \ell_c(\bY,\bZ; \theta)  \right] $$
 \item[$\bullet$]\textbf{Step M}: 
 $$ \theta^{(t)} = \arg \max_{\theta} Q(\theta | \theta^{(t-1)})$$
 \end{itemize}
% 
%
% 
\end{block}
 
 \end{frame}
  %------------------------------------------------------------------------------------------------------
 \begin{frame}{Limitations of standard EM}

\begin{itemize}
\item Step $E$ requires the computation of    $ \mathbb E_{\color{dgreen}\bZ | \bX, \theta^{(t-1)} } \left[\log \ell_c(\bX,\bZ; \theta)  \right] $
 \item However, once conditioned by par  $\bX$,  the  $\bZ$ are not independent anymore: complex  distribution if    $K$ and $n$ big. 
  \end{itemize}
 \end{frame}
 
 %------------------------------------------------------------------------------------------------------

 \begin{frame}{Variational EM  : maximization of a lower bound}


\textcolor{dgreen}{\textbf{Idea}} : replace the complicated distribution $p(\cdot | \Xall; \theta) = [\bZ | \bX, \theta]$ by a simpler one. 


Let $\mathcal{R}_{\Xall,\btau}$ be any distribution on   $\Zall$


\begin{block}{Central identity}
\begin{eqnarray*}
\mathcal{I}_{\theta}(\mathcal{R}_{\Xall,\btau}) &=& \log \ell(\Xall ; \theta) -   \mathbf{KL}[\mathcal{R}_{\Xall,\btau}, p(\cdot | \Xall; \theta)] \color{dgreen}\quad \leq   \log \ell(\Xall ; \theta)   \\
&=& \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} \left[\log \ell_c(\bX,\bZ; \theta)   \right]  -   \sum_{\Zall} \mathcal{R}_{\Xall,\btau}(\bZ)  \log \mathcal{R}_{\Xall,\btau}({\bZ}) \\
&=& \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} \left[\log \ell_c(\bX,\bZ; \theta)   \right]  +  \mathcal{H}\left(\mathcal{R}_{\Xall,\btau}(\bZ)\right) 
\end{eqnarray*}
\end{block} 

\textbf{Note that}:  
$$\mathcal{I}_{\theta}(\mathcal{R}_{\Xall,\btau})  = \log \ell(\Xall; \theta) \Leftrightarrow \mathcal{R}_{\Xall,\btau} = p(\cdot | \Xall; \theta)$$ 


\end{frame}

%----------------------------------------------------------------------------------------------
 \begin{frame}{Proof}

By Bayes
\begin{eqnarray*}
\log \ell_c(\bX,\bZ; \theta)&=& \log  p(\bZ | \Xall; \theta) +   \log \ell(\Xall ; \theta)   \\
 \log \ell(\Xall ; \theta) &=& \log \ell_c(\bX,\bZ; \theta) -  \log  p(\bZ | \Xall; \theta)
\end{eqnarray*}

By integration against $\mathcal{R}_{\Xall,\btau}$ : 
\begin{eqnarray*}
 \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [ \log  \ell(\Xall ; \theta)] &=&  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [\log \ell_c(\bX,\bZ; \theta)] -  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [ \log  p(\bZ | \Xall; \theta)] \\
 \log \ell(\Xall ; \theta) &=&  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [\log \ell_c(\bX,\bZ; \theta)] -  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [ \log  p(\cdot | \Xall; \theta)]
\end{eqnarray*}

As a consequence: 
\begin{eqnarray*}
\mathcal{I}_{\theta}(\mathcal{R}_{\Xall,\btau}) &=& \log \ell(\Xall ; \theta) -   \mathbf{KL}[\mathcal{R}_{\Xall,\btau}, p(\cdot | \Xall; \theta)] \\
 &=& \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [\log \ell_c(\bX,\bZ; \theta)] -  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [ \log  p(\bZ | \Xall; \theta)] \\
&& -   \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} \left[\log \frac{\mathcal{R}_{\Xall,\btau}(\bZ)} { p(\bZ | \Xall; \theta)}\right]\\
&=&  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [\log \ell_c(\bX,\bZ; \theta)] -  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [ \log  p(\bZ | \Xall; \theta)] \\
&& -   \underbrace{\mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [\log \mathcal{R}_{\Xall,\btau}(\bZ)]}_{  \mathcal{H}\left(\mathcal{R}_{\Xall,\btau}(\bZ)\right) } +  \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} [\log p(\bZ | \Xall; \theta)]
\end{eqnarray*}




  \end{frame}





  %------------------------------------------------------------------------------------------------------
 \begin{frame}{Variational EM }
 

\begin{itemize}
\item Maximization of  $\log \ell(\Xall ; \theta)$  w.r.t.  $\theta$ replaced by maximization of the lower bound $\mathcal{I}_{\theta}(\mathcal{R}_{\Xall,\btau}) $  w.r.t.  $\tau$ and $\theta$. 
\item \textbf{Benefit} : we choose   $\mathcal{R}_{\Xall,\btau}$  such that the maximization calculus can be done explicitly
 \begin{itemize}
 \item In our case: mean field approximation : neglect dependencies between the  $(Z_i)$ 
 $$P_{\mathcal{R}_{\Xall,\btau}}(Z^q_i=k) = \tau_{ik}^q$$
  \end{itemize}


  % $\mathcal{R}_{\Xall,\btau}$ approximation of $p(\cdot | \Xall; \theta)$ in a certain class of distributions $\mathcal{P}$

 \end{itemize}
  \end{frame}
  %------------------------------------------------------------------------------------------------------
 \begin{frame}{Variational  EM}


\begin{block}{Algorithm}
 \noindent At iteration $(t)$, given the current value  $(\theta^{(t-1)},\mathcal{R}_{\Xall, \btau^{(t-1)}})$,
\begin{enumerate}
\item[$\bullet$]\textbf{Step 1} Maximization w.r.t. $\tau$

\begin{eqnarray*}
\btau^{(t)}  &=&  \arg \max_{\btau  \in \mathcal{T}}  \mathcal{I}_{\theta^{(t-1)}}(\mathcal{R}_{\Xall,\btau})\\
 &=&  \arg \max_{\btau  \in \mathcal{T}}   \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau}} \left[\log \ell_c(\bX,\bZ;  \theta^{(t-1)})   \right] +  \mathcal{H}\left(\mathcal{R}_{\Xall,\btau}(\bZ)\right) \\
&=&  \arg \max_{\btau  \in \mathcal{T}}  \log \ell(\Xall ; \theta^{(t-1)})  -  \mathbf{KL}[\mathcal{R}_{\Xall, \btau}, p(\cdot | \Xall; \theta^{(t-1)})]\\ 
&=& \arg \min_{\btau  \in \mathcal{T}}\mathbf{KL}[\mathcal{R}_{\Xall, \btau}, p(\cdot | \Xall; \theta^{(t-1)})]\\ 
 \end{eqnarray*}
 \end{enumerate}

 \end{block} 
 \end{frame}

  %------------------------------------------------------------------------------------------------------

 \begin{frame}{Variational  EM}


\begin{block}{Algorithm}
\begin{enumerate}
 \item[$\bullet$]\textbf{Step 2} Maximization  w.r.t.  $\theta$
 \begin{eqnarray*}
 \theta^{(t)} &=& \arg \max_{\theta}   \mathcal{I}_{\theta}(\mathcal{R}_{\Xall,\btau^{(t)}}) \\
 &=&   \arg \max_{\theta} \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau^{(t)}}} \left[\log \ell_c(\bX,\bZ;  \theta)   \right]  +   \mathcal{H}\left(\mathcal{R}_{\Xall,\btau^{(t)}}(\bZ)\right)\\
&=&  \arg \max_{\theta} \mathbb{E}_{\color{dgreen}\mathcal{R}_{\Xall,\btau^{(t)}}} \left[\log \ell_c(\bX,\bZ;  \theta)   \right]  
 \end{eqnarray*}
 
\end{enumerate}

 \end{block} 
 \end{frame}
  %------------------------------------------------------------------------------------------------------
\begin{frame}{In practice}
\begin{itemize}
\item Really fast
\item Strongly depend on the initial values
\end{itemize}

\end{frame}
 
 \subsection{Model selection}
   %------------------------------------------------------------------------------------------------------
 \begin{frame}{ Penalized likelihood criterion}

 \begin{itemize}
 \item  Selection of the number of clusters  $K$ (or $K_1$, $K_2$ in the LBM)
\item   Integrated Classification Likelihood (ICL)   \textcolor{blue}{\cite{biernacki2000assessing}}
 

\begin{equation}\label{eq:ICL}
ICL(\M) =\log  \ell_c(\Xall,\hat{\bZ}; \hat \theta_{\bK})-  \pen(\M)
\end{equation}
 where  \begin{equation}\label{eq:Zhat}
\hat{Z}_i ^q = \argmax_{k \in \{1, \dots, K_q\}}  \hat{\tau}_{ik}^q. 
\end{equation} 
\item   Integrated Complete Likelihood (ICL)  % \textcolor{blue}{\cite{biernacki2000assessing}}

 

\begin{equation}\label{eq:ICL}
ICL(\M) =\mathbb{E}_{p(\cdot | \bY, \hat \theta_{\bK})}[\log  \ell_c(\Xall,\hat{\bZ}; \hat \theta_{\bK})-  \pen(\M)
\end{equation}
 \end{itemize}

\end{frame}


   %------------------------------------------------------------------------------------------------------
 \begin{frame}{Expression of the penalization}
 
\textcolor{dgreen}{ \textbf{For SBM } }

$$ pen_{\mathcal{M}} = \left\{ 
\begin{array}{ll}
- \frac{1}{2}\left\{ (K-1)\log(n)  +K^2   \log \left( n^2-n \right)\right\} & \mbox{for directed network}\\
 - \frac{1}{2}\left\{ \underbrace{(K-1)\log(n) }_{\mbox{\textcolor{dgreen}{Clust. }}} + \frac{K(K+1)}{2}   \log \left(\frac{ n^2-n }{2}\right)\right\} & \mbox{for undirected network}\\
\end{array}
\right.
$$
 

\textcolor{dgreen}{ \textbf{For LBM } }
%
\begin{eqnarray*}
 pen_{\mathcal{M}} =  -  \frac{1}{2}&& \left\{  \underbrace{ (K_1-1)\log(n_1) +  (K_2-1)\log(n_2)  }_{\mbox{\textcolor{dgreen}{Bi-Clust. }}} \right. \\
& &  + \left. \underbrace{ (K_1  K_2)    \log ( n_1   n_2)} _{\mbox{\textcolor{dgreen}{Connection }}} \right\} 
 \end{eqnarray*}

\end{frame}
 

   %------------------------------------------------------------------------------------------------------

\begin{frame}{Advantages of ICL}

 
\begin{itemize}
\item its capacity to outline the clustering structure in networks% in \cite{Daudinetal2008} (for simple networks),  \cite{keribin2015} (for bipartite networks)  or \cite{mariadassou2010} for valued networks.  
\item Involves a trade-off between goodness of fit and model complexity
\item ICL values :   goodness of fit  AND clustering  sharpness.
 
\end{itemize}

\end{frame}

 


  %------------------------------------------------------------------------------------------------------

 \begin{frame}{Comments on the   ICL versus BIC}

\begin{block}{Conjecture}
\begin{eqnarray*}
 BIC(\Mcal)  &=&  \log \ell(\Xall; \hat{\theta}, \Mcal) - \mbox{pen}(\Mcal)
\end{eqnarray*}
with the same penalty
 \end{block}

\begin{itemize}
\item Under this conjecture
\begin{eqnarray*}
 ICL(\Mcal)  &= & BIC(\Mcal)  +   \sum_{\Zall} p(\bZ | \Xall;\hat \theta_{\bK}) \log p(\bZ | \Xall; \hat \theta_{\bK})\\
 &=& BIC(\Mcal)  -   \mathcal{H}( p(\cdot | \Xall; \theta)) 
\end{eqnarray*}
\item As a consequence, because of the entropy,  ICL  will encourage clustering with well-separated groups 
\item 
$$ 
 \widehat{ICL}(\mathcal{M})  =BIC(\mathcal{M})  +   \sum_{\Zall} \mathcal{R}_{\Xall}(\bZ,\widehat{\btau})  \log \mathcal{R}_{\Xall,\widehat{\btau}}({\bZ}) -  \mathbf{KL}[\mathcal{R}_{\Xall,\widehat{\btau}}, p(\cdot | \Xall;\widehat{\theta})]\,. 
$$

\end{itemize}

 
 \end{frame}
 
 

   %------------------------------------------------------------------------------------------------------



\begin{frame}{Algorithm in practice}  
\begin{itemize}
\item Going trough the models and initiate VEM at the same time
\item Bounds on $K$ :  $\{K_{ \min},\dots, K_{\max}\}$
\end{itemize}

\begin{block}{Stepwise procedure}
Starting from  $K$

\begin{itemize}
\item \textbf{Split} : if $K<K_{\max}$
\begin{itemize}
\item Maximize the likelihood (lower bound) of  $\mathcal{M}_{K+1}$
\item  $K$ initializations of the VEM are proposed :  split each cluster into $2$ clusters  
\end{itemize}
\item \textbf{Merge} :  If $K>K_{\min}$
\begin{itemize}
\item Maximize the likelihood (lower bound) of   model  $\mathcal{M}_{K-1}$
\item  $\frac{K(K-1)}{2}$ initializations of the VEM are proposed :   merging all the possible pairs of  clusters 
 \end{itemize}
\end{itemize}

\end{block}
 \end{frame}


\begin{frame}\frametitle{Theoretical properties for SBM}
\begin{itemize}
\item Identifiability and a first consistency result by \color{blue} \cite{celisse2012consistency} \color{black}
\item Consistency of the posterior distribution of the latent variables \color{blue} \cite{mariadassou2015convergence} \color{black}
\item Consistency and properties of the variational estimators \color{blue} \cite{bickel2013asymptotic} \color{black}
\end{itemize}
\end{frame}
%--------------------------------------------------- 
\begin{frame}{Other extensions}

\begin{itemize}
\item  Time evolving networks \textcolor{blue}{Matias} 
\item  Multipartite networks (\textcolor{blue}{R-package GREMLIN, Bar-Hen, Barbillon, Donnet}) 
\item Multilevel networks (individuals and organizations)  (\textcolor{blue}{Chabbert-Liddell})
 \item Missing data in the network,
\end{itemize}
\end{frame}

%------------------------------------------ 
\begin{frame}
 \frametitle{Probabilistic model for networks in a nutshell}
 
 SBM/LBM
 \begin{itemize}
  \item generative models,
  \item flexible,
  \item comprehensive models which can be linked to a lot of classical descriptors.
  
 \end{itemize}
\end{frame}


\begin{frame}[allowframebreaks]{References}
\bibliographystyle{apalike}
 \small{\bibliography{biblio_ecostat}}
  \end{frame}
  
  
  




\end{document}
